{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load nb_init.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = Path.cwd().parent\n",
    "config_dir = base_dir / \"config\"\n",
    "data_dir = base_dir / \"data\"\n",
    "models_dir = base_dir / \"models\"\n",
    "logs_dir = base_dir / \"logs\"\n",
    "images_input_dir = data_dir / \"COVID19\"\n",
    "preprocessed_dir = data_dir / \"preprocessed\"\n",
    "output_dir = data_dir / \"output\"\n",
    "\n",
    "# Directories used to train the CNN (image by image) \n",
    "cnn_data_dir = data_dir / \"modelling\" / \"cnn\"\n",
    "cnn_train_dir = cnn_data_dir / \"train\"\n",
    "cnn_test_dir = cnn_data_dir / \"test\"\n",
    "\n",
    "metadata_file = images_input_dir / \"metadata.csv\"\n",
    "labels_file = images_input_dir / \"unzip_filenames.csv\"\n",
    "preprocessed_labels_file = preprocessed_dir / \"labels.parquet\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "config_file = config_dir / \"tfg.conf\"\n",
    "\n",
    "from pyhocon import ConfigFactory\n",
    "config = ConfigFactory.parse_file(config_file)\n",
    "\n",
    "import sys\n",
    "\n",
    "if str(base_dir / \"src\") not in sys.path:\n",
    "    sys.path.append(str(base_dir / \"src\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('tfg',\n",
       "              OrderedDict([('seed', 42),\n",
       "                           ('eda',\n",
       "                            OrderedDict([('csv_options',\n",
       "                                          OrderedDict([('header', 'true'),\n",
       "                                                       ('sep', ','),\n",
       "                                                       ('inferSchema',\n",
       "                                                        'true')]))])),\n",
       "                           ('training',\n",
       "                            OrderedDict([('test_fraction', 0.1),\n",
       "                                         ('val_fraction', 0.1),\n",
       "                                         ('images_per_clip', 70),\n",
       "                                         ('batch_size', 32)]))])),\n",
       "             ('data',\n",
       "              OrderedDict([('train_files_df',\n",
       "                            OrderedDict([('path',\n",
       "                                          'preprocessed/training_files_df.csv')])),\n",
       "                           ('test_files_df',\n",
       "                            OrderedDict([('path',\n",
       "                                          'preprocessed/test_files_df.csv')]))]))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.as_plain_ordered_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.235:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5ea721d970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfg import DataRepository\n",
    "\n",
    "repo = DataRepository(config=config, base_data_path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-----+---------+\n",
      "|patient_id|scan_id|n_slice|label|num_clips|\n",
      "+----------+-------+-------+-----+---------+\n",
      "|         0|   3131|    285|   CP|        5|\n",
      "|         0|   3132|     42|   CP|        1|\n",
      "|         0|   3133|    290|   CP|        5|\n",
      "|         0|   3134|     37|   CP|        1|\n",
      "|         0|   3135|    269|   CP|        4|\n",
      "+----------+-------+-------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = spark.read.parquet(str(preprocessed_labels_file))\n",
    "\n",
    "labels.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4178"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = labels.count()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "| label|count|   pct|\n",
      "+------+-----+------+\n",
      "|    CP| 1556|0.3724|\n",
      "|   NCP| 1544|0.3696|\n",
      "|Normal| 1078| 0.258|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round((F.count(\"*\") / num_labels), 4).alias(\"pct\"),\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2742"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.select(\"patient_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split patient ids into train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config.get_int(\"tfg.seed\")\n",
    "test_fraction = config.get_float(\"tfg.training.test_fraction\")\n",
    "train_fraction = 1 - test_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows: 3752\n",
      "Test rows: 426\n",
      "+----------+-------+-------+-----+---------+\n",
      "|patient_id|scan_id|n_slice|label|num_clips|\n",
      "+----------+-------+-------+-----+---------+\n",
      "|         0|   3131|    285|   CP|        5|\n",
      "|         0|   3132|     42|   CP|        1|\n",
      "|         0|   3133|    290|   CP|        5|\n",
      "|         0|   3134|     37|   CP|        1|\n",
      "|         0|   3135|    269|   CP|        4|\n",
      "|         0|   3136|    290|   CP|        5|\n",
      "|         0|   3137|     37|   CP|        1|\n",
      "|         0|   3138|    245|   CP|        4|\n",
      "|         0|   3139|     39|   CP|        1|\n",
      "|         0|   3140|    269|   CP|        4|\n",
      "+----------+-------+-------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+-------+-------+-----+---------+\n",
      "|patient_id|scan_id|n_slice|label|num_clips|\n",
      "+----------+-------+-------+-----+---------+\n",
      "|         1|   3143|    300|   CP|        5|\n",
      "|         1|   3144|    248|   CP|        4|\n",
      "|         1|   3145|    248|   CP|        4|\n",
      "|         1|   3146|     70|   CP|        1|\n",
      "|         1|   3147|     70|   CP|        1|\n",
      "|      1070|   3112|    104|   CP|        2|\n",
      "|      1081|   3126|     68|   CP|        1|\n",
      "|      1082|   3127|     74|   CP|        2|\n",
      "|      1399|   3858|     45|   CP|        1|\n",
      "|      1399|   3859|     45|   CP|        1|\n",
      "+----------+-------+-------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patient_ids = labels.select(\"patient_id\").distinct()\n",
    "\n",
    "train_test_id_dfs = patient_ids.randomSplit([train_fraction, test_fraction], seed=seed)\n",
    "train_ids = train_test_id_dfs[0]\n",
    "test_ids =  train_test_id_dfs[1]\n",
    "\n",
    "train_labels = labels.join(train_ids, [\"patient_id\"], \"inner\")\n",
    "test_labels = labels.join(test_ids, [\"patient_id\"], \"inner\")\n",
    "\n",
    "train_count = train_labels.count()\n",
    "test_count = test_labels.count()\n",
    "\n",
    "print(f\"Training rows: {train_count}\")\n",
    "print(f\"Test rows: {test_count}\")\n",
    "\n",
    "train_labels.show(10)\n",
    "test_labels.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train counts and percentages\n",
      "+------+-----+----+\n",
      "| label|count| pct|\n",
      "+------+-----+----+\n",
      "|    CP| 1381|0.37|\n",
      "|   NCP| 1387|0.37|\n",
      "|Normal|  984|0.26|\n",
      "+------+-----+----+\n",
      "\n",
      "Test counts and labels\n",
      "+------+-----+----+\n",
      "| label|count| pct|\n",
      "+------+-----+----+\n",
      "|    CP|  175|0.41|\n",
      "|   NCP|  157|0.37|\n",
      "|Normal|   94|0.22|\n",
      "+------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train counts and percentages\")\n",
    "train_labels\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round((F.count(\"*\") / train_count), 2).alias(\"pct\"),\n",
    "    )\\\n",
    "    .show()\n",
    "print(\"Test counts and labels\")\n",
    "test_labels\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round((F.count(\"*\") / test_count), 2).alias(\"pct\"),\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datasets for the CNN\n",
    "\n",
    "We'll put all the images in our train and test sets into the directory for the cnn modelling. The directory structure will be of this form:\n",
    "\n",
    "- ```data/modelling/cnn```\n",
    "    - ```train|test```\n",
    "        - ```CP|NCP|Normal```\n",
    "            - ```[PATIENT_ID]_[SCAN_ID]_[SEQUENCE_NUMBER].png```\n",
    "\n",
    "The input data is in the form ```[LABEL]/[PATIENT_ID]/[SCAN_ID]/[SEQ_NUMBER].png```.\n",
    "The data files for the training will be in the form ```[TRAIN|TEST]/[LABEL]/[PATIENT_ID]_[SCAN_ID]_[SEQ_NUMBER].png```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Observation:\n",
    "    patient_id: int\n",
    "    scan_id: int\n",
    "    n_slice: int\n",
    "    num_clips: int\n",
    "    label: str\n",
    "\n",
    "    @staticmethod\n",
    "    def from_row(r: Row) -> \"Observation\":\n",
    "        return Observation(\n",
    "            patient_id=r.patient_id,\n",
    "            scan_id=r.scan_id,\n",
    "            n_slice=r.n_slice,\n",
    "            num_clips=r.num_clips,\n",
    "            label=r.label,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_df(config, labels):\n",
    "    raw_images = {\n",
    "        \"label\": [],\n",
    "        \"file\": [],\n",
    "        \"patient_id\": [],\n",
    "        \"scan_id\": [],\n",
    "        \"n_slice\": [],\n",
    "        \"num_clips\": [],\n",
    "        \"seq_num\": [],\n",
    "        \"clip_num\": [],\n",
    "    }\n",
    "\n",
    "    IMAGES_PER_CLIP = config.get_int(\"tfg.training.images_per_clip\")\n",
    "\n",
    "    for r in labels.collect():\n",
    "        obs = Observation.from_row(r)\n",
    "        scan_path = Path(f\"{obs.label}/{obs.patient_id}/{obs.scan_id}\")\n",
    "        absolute_scan_path = images_input_dir / scan_path\n",
    "        # different directories have different formats\n",
    "        img_ext = next(absolute_scan_path.glob(\"*.*\")).suffix\n",
    "\n",
    "        scan_images = []\n",
    "        seq_nums = []\n",
    "        clip_nums = []\n",
    "\n",
    "        seq_num = 0\n",
    "        images_input_dir_str = str(images_input_dir)\n",
    "        path_offset = len(images_input_dir_str) + 1\n",
    "        for seq_num, img in enumerate(absolute_scan_path.glob(f\"*{img_ext}\")):\n",
    "#        for seq_num in range(0, obs.n_slice):\n",
    "            #img = scan_path / f\"{seq_num:04d}{img_ext}\"\n",
    "            img_to_append = str(img)[path_offset:]\n",
    "            scan_images.append(img_to_append)\n",
    "            seq_nums.append(seq_num)\n",
    "            clip_nums.append(seq_num // IMAGES_PER_CLIP)\n",
    "            seq_num = seq_num + 1\n",
    "        \n",
    "#         print(seq_num, scan_images[-1])\n",
    "        \n",
    "        raw_images[\"label\"].extend([obs.label] * obs.n_slice)\n",
    "        raw_images[\"file\"].extend(scan_images)\n",
    "        raw_images[\"patient_id\"].extend([obs.patient_id] * obs.n_slice)\n",
    "        raw_images[\"scan_id\"].extend([obs.scan_id] * obs.n_slice)\n",
    "        raw_images[\"n_slice\"].extend([obs.n_slice] * obs.n_slice)\n",
    "        raw_images[\"num_clips\"].extend([obs.patient_id] * obs.n_slice)\n",
    "        raw_images[\"seq_num\"].extend(seq_nums)\n",
    "        raw_images[\"clip_num\"].extend(clip_nums)\n",
    "        \n",
    "    return pd.DataFrame(raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371114, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0275.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0064.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0083.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0127.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371109</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1924/379/0014.png</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>1924</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371110</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1924/379/0001.png</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>1924</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371111</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1924/379/0027.png</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>1924</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371112</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1924/379/0031.png</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>1924</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371113</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1924/379/0057.png</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>1924</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371114 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                      file  patient_id  scan_id  n_slice  \\\n",
       "0           CP        CP/0/3131/0275.png           0     3131      285   \n",
       "1           CP        CP/0/3131/0064.png           0     3131      285   \n",
       "2           CP        CP/0/3131/0083.png           0     3131      285   \n",
       "3           CP        CP/0/3131/0160.png           0     3131      285   \n",
       "4           CP        CP/0/3131/0127.png           0     3131      285   \n",
       "...        ...                       ...         ...      ...      ...   \n",
       "371109  Normal  Normal/1924/379/0014.png        1924      379       98   \n",
       "371110  Normal  Normal/1924/379/0001.png        1924      379       98   \n",
       "371111  Normal  Normal/1924/379/0027.png        1924      379       98   \n",
       "371112  Normal  Normal/1924/379/0031.png        1924      379       98   \n",
       "371113  Normal  Normal/1924/379/0057.png        1924      379       98   \n",
       "\n",
       "        num_clips  seq_num  clip_num  \n",
       "0               0        0         0  \n",
       "1               0        1         0  \n",
       "2               0        2         0  \n",
       "3               0        3         0  \n",
       "4               0        4         0  \n",
       "...           ...      ...       ...  \n",
       "371109       1924       93         1  \n",
       "371110       1924       94         1  \n",
       "371111       1924       95         1  \n",
       "371112       1924       96         1  \n",
       "371113       1924       97         1  \n",
       "\n",
       "[371114 rows x 8 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = create_df(config, train_labels)\n",
    "print(f\"{train_df.shape}\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"train_files_df\", train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40415, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0275.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0064.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0083.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0160.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0286.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40410</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1917/372/0014.png</td>\n",
       "      <td>1917</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>1917</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40411</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1917/372/0001.png</td>\n",
       "      <td>1917</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>1917</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40412</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1917/372/0027.png</td>\n",
       "      <td>1917</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>1917</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40413</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1917/372/0031.png</td>\n",
       "      <td>1917</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>1917</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40414</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal/1917/372/0057.png</td>\n",
       "      <td>1917</td>\n",
       "      <td>372</td>\n",
       "      <td>96</td>\n",
       "      <td>1917</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40415 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                      file  patient_id  scan_id  n_slice  \\\n",
       "0          CP        CP/1/3143/0275.png           1     3143      300   \n",
       "1          CP        CP/1/3143/0064.png           1     3143      300   \n",
       "2          CP        CP/1/3143/0083.png           1     3143      300   \n",
       "3          CP        CP/1/3143/0160.png           1     3143      300   \n",
       "4          CP        CP/1/3143/0286.png           1     3143      300   \n",
       "...       ...                       ...         ...      ...      ...   \n",
       "40410  Normal  Normal/1917/372/0014.png        1917      372       96   \n",
       "40411  Normal  Normal/1917/372/0001.png        1917      372       96   \n",
       "40412  Normal  Normal/1917/372/0027.png        1917      372       96   \n",
       "40413  Normal  Normal/1917/372/0031.png        1917      372       96   \n",
       "40414  Normal  Normal/1917/372/0057.png        1917      372       96   \n",
       "\n",
       "       num_clips  seq_num  clip_num  \n",
       "0              1        0         0  \n",
       "1              1        1         0  \n",
       "2              1        2         0  \n",
       "3              1        3         0  \n",
       "4              1        4         0  \n",
       "...          ...      ...       ...  \n",
       "40410       1917       91         1  \n",
       "40411       1917       92         1  \n",
       "40412       1917       93         1  \n",
       "40413       1917       94         1  \n",
       "40414       1917       95         1  \n",
       "\n",
       "[40415 rows x 8 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = create_df(config, test_labels)\n",
    "print(f\"{test_df.shape}\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"test_files_df\", test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0275.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0064.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0083.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0127.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                file  patient_id  scan_id  n_slice  num_clips  seq_num  \\\n",
       "0    CP  CP/0/3131/0275.png           0     3131      285          0        0   \n",
       "1    CP  CP/0/3131/0064.png           0     3131      285          0        1   \n",
       "2    CP  CP/0/3131/0083.png           0     3131      285          0        2   \n",
       "3    CP  CP/0/3131/0160.png           0     3131      285          0        3   \n",
       "4    CP  CP/0/3131/0127.png           0     3131      285          0        4   \n",
       "\n",
       "   clip_num  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = repo.load(\"train_files_df\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fce4c7eb2b44bdab9fbeb1230db340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_sizes = set()\n",
    "\n",
    "for r in tqdm(train_df.drop_duplicates([\"patient_id\", \"scan_id\"]).iterrows()):\n",
    "    img_path = images_input_dir / r[1][\"file\"]\n",
    "    img_sizes.add(load_img(img_path).size)\n",
    "\n",
    "img_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9a3624658547d1ae4f858c5b204edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+----------+-------+-------+-----+---------+\n",
      "|patient_id|scan_id|n_slice|label|num_clips|\n",
      "+----------+-------+-------+-----+---------+\n",
      "|       843|   2358|    279|  NCP|        4|\n",
      "+----------+-------+-------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Some directories needed fixing, images did not start at 0000...\n",
    "\n",
    "# from tqdm.notebook import trange\n",
    "# label = \"NCP\"\n",
    "# patient_id = \"843\"\n",
    "# scan_id = \"2358\"\n",
    "# path = Path(f\"/data/projects/tfg/data/COVID19/{label}/{patient_id}/{scan_id}/\")\n",
    "\n",
    "# start = 243\n",
    "# end = 279\n",
    "# offset = 1#start\n",
    "# ext = \"JPG\"\n",
    "# for i in trange(start, end + 1):\n",
    "#     src_filename = path / f\"{i:04d}.{ext}\"\n",
    "#     target_filename = path / f\"{i-offset:04d}.{ext}\"\n",
    "# #     print(f\"src: {src_filename}\")\n",
    "# #     print(f\"target: {target_filename}\")\n",
    "# #     break\n",
    "#     !mv {src_filename} {target_filename}\n",
    "\n",
    "# train_labels.filter(f\"patient_id = {patient_id} and scan_id = {scan_id}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef419e86e964c06a46feb6282ddac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "missing_images = []\n",
    "\n",
    "for idx, r in tqdm(train_df.iterrows()):\n",
    "    img_path = images_input_dir / r[\"file\"]\n",
    "    if not img_path.exists():\n",
    "        missing_images.append(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(missing_images) == 0, \"There are missing images in the dataframe!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 334003 validated image filenames belonging to 3 classes.\n",
      "Found 37111 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "seed = config.get_int(\"tfg.seed\")\n",
    "val_fraction = config.get_float(\"tfg.training.val_fraction\")\n",
    "datagen = ImageDataGenerator(rescale=1./255.,validation_split=val_fraction)\n",
    "batch_size = config.get_int(\"tfg.training.batch_size\")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=str(images_input_dir),\n",
    "    x_col=\"file\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(512, 512))\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=str(images_input_dir),\n",
    "    x_col=\"file\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers as reg\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = keras.Input(shape=(512, 512, 3), name=\"input_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 16\n",
    "initial_dense_features = 256\n",
    "num_features = 64\n",
    "num_classes = 3\n",
    "num_layers = 0\n",
    "cnn_net = input_images\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\", kernel_regularizer=reg.l2(l=0.01))(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "filters = filters * 2\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\", kernel_regularizer=reg.l2(l=0.01))(cnn_net)\n",
    "cnn_net = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")(cnn_net)\n",
    "num_layers = num_layers + 1\n",
    "\n",
    "cnn_net = layers.Flatten(name=f\"flatten\")(cnn_net)\n",
    "\n",
    "cnn_net = layers.Dense(initial_dense_features, activation=\"relu\", name=\"dense_01\")(cnn_net)\n",
    "cnn_net = layers.Dropout(0.2, name=\"dropout_01\")(cnn_net)\n",
    "\n",
    "cnn_net = layers.Dense(initial_dense_features // 2, activation=\"relu\", name=\"dense_02\")(cnn_net)\n",
    "cnn_net = layers.Dropout(0.2, name=\"dropout_02\")(cnn_net)\n",
    "\n",
    "\n",
    "cnn_net = layers.Dense(num_features, activation=\"relu\", name=\"dense_03\")(cnn_net)\n",
    "cnn_net = layers.Dropout(0.2, name=\"dropout_03\")(cnn_net)\n",
    "\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\", name=\"output\")\n",
    "outputs = output_layer(cnn_net)\n",
    "\n",
    "model = keras.Model(inputs=input_images, outputs=outputs, name=\"covid_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"covid_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_images (InputLayer)    [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_01 (Conv2D)           (None, 512, 512, 16)      448       \n",
      "_________________________________________________________________\n",
      "maxpool2d_01 (MaxPooling2D)  (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_02 (Conv2D)           (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "maxpool2d_02 (MaxPooling2D)  (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_03 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "maxpool2d_03 (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_04 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "maxpool2d_04 (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_05 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "maxpool2d_05 (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_06 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "maxpool2d_06 (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_07 (Conv2D)           (None, 8, 8, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "maxpool2d_07 (MaxPooling2D)  (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_01 (Dense)             (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_01 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_02 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_02 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_03 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_03 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 10,528,291\n",
      "Trainable params: 10,528,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10437"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_dir = models_dir / \"cnn\"\n",
    "cnn_checkpoint_dir = cnn_model_dir / \"checkpoint\"\n",
    "cnn_checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "cnn_logs_dir = logs_dir / \"cnn\"\n",
    "cnn_logs_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = callbacks.ModelCheckpoint(\n",
    "    str(cnn_checkpoint_dir),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "tensorboard_logger = callbacks.TensorBoard(\n",
    "    log_dir=str(cnn_logs_dir),\n",
    "    histogram_freq=1,\n",
    "    write_graph=False,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "model_callbacks = [checkpointer, tensorboard_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   50/10437 [..............................] - ETA: 2:04:56 - loss: 3.1830 - categorical_accuracy: 0.4225"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "fit_history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                    callbacks=model_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-34643bfdede1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mfilters\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconv_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"conv2d_{num_layers+1:02d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcnn_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilters\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmax_pool_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"maxpool2d_{num_layers+1:02d}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    182\u001b[0m     self._conv_op_data_format = conv_utils.convert_data_format(\n\u001b[1;32m    183\u001b[0m         self.data_format, self.rank + 2)\n\u001b[0;32m--> 184\u001b[0;31m     self._convolution_op = nn_ops.Convolution(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mfilter_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m   1063\u001b[0m                                     filter_shape[num_spatial_dims]))\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     strides, dilation_rate = _get_strides_and_dilation_rate(\n\u001b[0m\u001b[1;32m   1066\u001b[0m         num_spatial_dims, strides, dilation_rate)\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_get_strides_and_dilation_rate\u001b[0;34m(num_spatial_dims, strides, dilation_rate)\u001b[0m\n\u001b[1;32m    752\u001b[0m                                                            num_spatial_dims))\n\u001b[1;32m    753\u001b[0m   \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all values of strides must be positive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filters = 16\n",
    "num_features = 100\n",
    "num_classes = 3\n",
    "num_layers = 0\n",
    "cnn_net = input_images\n",
    "while filters <= 256:\n",
    "    conv_layer = layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\", activation=\"relu\", name=f\"conv2d_{num_layers+1:02d}\")\n",
    "    cnn_net = conv_layer(cnn_net)\n",
    "    if filters < 256:\n",
    "        max_pool_layer = layers.MaxPool2D(2, name=f\"maxpool2d_{num_layers+1:02d}\")\n",
    "        cnn_net = max_pool_layer(cnn_net)\n",
    "        filters = filters * 2\n",
    "    num_layers += 1\n",
    "\n",
    "flatten_layer = layers.Flatten(name=\"flatten\")\n",
    "cnn_net = flatten_layer(cnn_net)\n",
    "\n",
    "dense_layer = layers.Dense(filters, activation=\"relu\", name=\"dense_01\")\n",
    "cnn_net = dense_layer(cnn_net)\n",
    "\n",
    "dense_layer2 = layers.Dense(num_features, activation=\"relu\", name=\"dense_02\")\n",
    "cnn_net = dense_layer2(cnn_net)\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\", name=\"output\")\n",
    "outputs = output_layer(cnn_net)\n",
    "\n",
    "model = keras.Model(inputs=input_images, outputs=outputs, name=\"covid_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'maxpool2d_05/Identity:0' shape=(None, 14, 14, 256) dtype=float32>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/Identity:0' shape=(None, 512, 512, 6) dtype=float32>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_input_dir = data_dir / \"COVID19\"\n",
    "# Directories used to train the CNN (image by image) \n",
    "cnn_data_dir = data_dir / \"modelling\" / \"cnn\"\n",
    "cnn_train_dir = cnn_data_dir / \"train\"\n",
    "cnn_test_dir = cnn_data_dir / \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jpg'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(scan_input_dir.glob(\"*.*\")).suffix.lstrip(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dcac0f7b594c5280948ce78b400fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Scans processed'), FloatProgress(value=0.0, max=3752.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-9bcda751e854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mimage_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0msave_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36msave_img\u001b[0;34m(path, x, data_format, file_format, scale, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m   image.save_img(path,\n\u001b[0m\u001b[1;32m    155\u001b[0m                  \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                  \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36msave_img\u001b[0;34m(path, x, data_format, file_format, scale, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                       'RGBA images, converting to RGB.')\n\u001b[1;32m     74\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2152\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "\n",
    "formats_to_check = [\"png\", \"PNG\", \"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"bmp\", \"BMP\"]\n",
    "image_sizes = set()\n",
    "\n",
    "for r in tqdm(train_labels.collect(), desc=\"Scans processed\"):\n",
    "    obs = Observation.from_row(r)\n",
    "    image_output_dir = cnn_train_dir / obs.label\n",
    "    scan_input_dir = images_input_dir / obs.label / str(obs.patient_id) / str(obs.scan_id)\n",
    "    for img_format in formats_to_check:\n",
    "        scan_images = list(scan_input_dir.glob(f\"*.{img_format}\"))\n",
    "        if any(scan_images):\n",
    "            break\n",
    "    \n",
    "    # If not, check for jpg\n",
    "    if not any(scan_images):\n",
    "        scan_images = list(scan_input_dir.glob(\"*.jpg\"))\n",
    "    \n",
    "    assert any(scan_images), \\\n",
    "        f\"Couldn't load images from {scan_input_dir}\"\n",
    "\n",
    "    for image in scan_images:\n",
    "        # Pick the file name\n",
    "        suffix = image.suffix\n",
    "        base_name = image.name[:-len(suffix)]\n",
    "        target_file = image_output_dir / f\"{obs.patient_id}_{obs.scan_id}_{base_name}.png\"\n",
    "\n",
    "        if not target_file.exists():\n",
    "            img = load_img(str(image))\n",
    "            img_array = img_to_array(img)\n",
    "            image_sizes.add(img_array.shape)\n",
    "            save_img(str(target_file), img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(512, 512, 3)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0032'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.name[:-len(image.suffix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for r in tqdm(test_labels.collect(), desc=\"Scans processed\"):\n",
    "    obs = Observation.from_row(r)\n",
    "    image_output_dir = cnn_test_dir / obs.label\n",
    "    scan_input_dir = images_input_dir / obs.label / str(obs.patient_id) / str(obs.scan_id)\n",
    "    # First, check for png images\n",
    "    scan_images = list(scan_input_dir.glob(\"*.png\"))\n",
    "    \n",
    "    # If not, check for jpg\n",
    "    if not any(scan_images):\n",
    "        scan_images = list(scan_input_dir.glob(\"*.jpg\"))\n",
    "    \n",
    "    assert any(scan_images), \\\n",
    "        f\"Couldn't load images from {scan_input_dir}\"\n",
    "\n",
    "    for image in scan_images:\n",
    "        # Pick the file name\n",
    "        base_name = image.name\n",
    "        target_file = image_output_dir / f\"{obs.patient_id}_{obs.scan_id}_{base_name}\"\n",
    "        shutil.copy(image, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = list(patient_input_dir.glob(\"*.png\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label(patient_id=0, scan_id=3131, n_slice=285, num_clips=5, label='CP')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label.from_row(train_labels.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'pyspark.sql.dataframe.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3ce759e50a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfg/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'pyspark.sql.dataframe.DataFrame'>"
     ]
    }
   ],
   "source": [
    "TODO:\n",
    "- Get unique patient ids into pandas\n",
    "- Split the ids into train/test\n",
    "- Divide labels into train_labels and test_labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split(labels, test_size=.1, random_state=config.get_int(\"tfg.seed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics\n",
    "## Metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id,scan_id,Age,Sex(Male1/Female2),Critical_illness,Liver_function,Lung_function,Progression (Days)\n",
      "1399,127,57,1,1,5,2,0.08\n"
     ]
    }
   ],
   "source": [
    "!head -n2 {metadata_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+------------------+----------------+--------------+-------------+------------------+\n",
      "|patient_id|scan_id|Age|Sex(Male1/Female2)|Critical_illness|Liver_function|Lung_function|Progression (Days)|\n",
      "+----------+-------+---+------------------+----------------+--------------+-------------+------------------+\n",
      "|      1399|    127| 57|                 1|               1|             5|            2|              0.08|\n",
      "|      1297|     82| 55|                 1|               1|             3|            2|              0.88|\n",
      "|      2255|    549|  3|                 1|               1|          null|         null|              0.02|\n",
      "|      1184|     26|  5|                 2|               1|             0|            2|              0.02|\n",
      "|      1186|     27|  2|                 2|               1|             2|            2|              0.02|\n",
      "+----------+-------+---+------------------+----------------+--------------+-------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata = spark.read\\\n",
    "    .options(**csv_options)\\\n",
    "    .csv(str(metadata_file))\n",
    "\n",
    "metadata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_id: integer (nullable = true)\n",
      " |-- scan_id: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex(Male1/Female2): integer (nullable = true)\n",
      " |-- Critical_illness: integer (nullable = true)\n",
      " |-- Liver_function: integer (nullable = true)\n",
      " |-- Lung_function: integer (nullable = true)\n",
      " |-- Progression (Days): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+---+------+----------------+--------------+-------------+----------------+\n",
      "|       id|patient_id|scan_id|age|gender|critical_illness|liver_function|lung_function|progression_days|\n",
      "+---------+----------+-------+---+------+----------------+--------------+-------------+----------------+\n",
      "|1399::127|      1399|    127| 57|     1|               1|             5|            2|            0.08|\n",
      "| 1297::82|      1297|     82| 55|     1|               1|             3|            2|            0.88|\n",
      "|2255::549|      2255|    549|  3|     1|               1|          null|         null|            0.02|\n",
      "| 1184::26|      1184|     26|  5|     2|               1|             0|            2|            0.02|\n",
      "| 1186::27|      1186|     27|  2|     2|               1|             2|            2|            0.02|\n",
      "+---------+----------+-------+---+------+----------------+--------------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_expr = \"CONCAT(patient_id, '::', scan_id) AS id\"\n",
    "metadata_exprs = [\n",
    "    id_expr,\n",
    "    \"patient_id AS patient_id\",\n",
    "    \"scan_id AS scan_id\",\n",
    "    \"Age AS age\",\n",
    "    \"`Sex(Male1/Female2)` AS gender\",\n",
    "    \"Critical_illness AS critical_illness\",\n",
    "    \"Liver_function AS liver_function\",\n",
    "    \"Lung_function AS lung_function\",\n",
    "    \"`Progression (Days)` AS progression_days\",\n",
    "]\n",
    "\n",
    "metadata = metadata.selectExpr(*metadata_exprs)\n",
    "\n",
    "metadata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----------+-------+-------+\n",
      "|zip_file|label|patient_id|scan_id|n_slice|\n",
      "+--------+-----+----------+-------+-------+\n",
      "|CP-1.zip|   CP|         0|   3131|    285|\n",
      "|CP-1.zip|   CP|         0|   3132|     42|\n",
      "|CP-1.zip|   CP|         0|   3133|    290|\n",
      "|CP-1.zip|   CP|         0|   3134|     37|\n",
      "|CP-1.zip|   CP|         0|   3135|    269|\n",
      "+--------+-----+----------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = spark.read.options(**csv_options).csv(str(labels_file))\n",
    "\n",
    "labels.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- zip_file: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- patient_id: integer (nullable = true)\n",
      " |-- scan_id: integer (nullable = true)\n",
      " |-- n_slice: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-----+\n",
      "|     id|patient_id|scan_id|n_slice|label|\n",
      "+-------+----------+-------+-------+-----+\n",
      "|0::3131|         0|   3131|    285|   CP|\n",
      "|0::3132|         0|   3132|     42|   CP|\n",
      "|0::3133|         0|   3133|    290|   CP|\n",
      "|0::3134|         0|   3134|     37|   CP|\n",
      "|0::3135|         0|   3135|    269|   CP|\n",
      "+-------+----------+-------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_expr = [\n",
    "    id_expr,\n",
    "    \"patient_id AS patient_id\",\n",
    "    \"scan_id AS scan_id\",\n",
    "    \"n_slice AS n_slice\",\n",
    "    \"label\",\n",
    "]\n",
    "\n",
    "labels = labels.selectExpr(*labels_expr)\n",
    "\n",
    "labels.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4178"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check overlap between labels and metadata\n",
    "\n",
    "Do we have demographics for patients for which we have data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have demographics for 378 / 4178 observations (9.05%)\n"
     ]
    }
   ],
   "source": [
    "total_labels = labels.count()\n",
    "total_labels_with_demo = labels.join(metadata, [\"patient_id\"], \"left_semi\").count()\n",
    "\n",
    "print(f\"We have demographics for {total_labels_with_demo} / {total_labels} observations ({100 * total_labels_with_demo / total_labels:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_metadata = labels.join(metadata, [\"patient_id\"], \"left_semi\")\n",
    "\n",
    "labels_with_metadata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| label|count|\n",
      "+------+-----+\n",
      "|    CP|  170|\n",
      "|   NCP|   13|\n",
      "|Normal|  195|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_with_metadata.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there also overlap on patient_id AND scan_id level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels.join(metadata, [\"patient_id\", \"scan_id\"], \"left_semi\").groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0::3131</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0::3132</td>\n",
       "      <td>0</td>\n",
       "      <td>3132</td>\n",
       "      <td>42</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0::3133</td>\n",
       "      <td>0</td>\n",
       "      <td>3133</td>\n",
       "      <td>290</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0::3134</td>\n",
       "      <td>0</td>\n",
       "      <td>3134</td>\n",
       "      <td>37</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0::3135</td>\n",
       "      <td>0</td>\n",
       "      <td>3135</td>\n",
       "      <td>269</td>\n",
       "      <td>CP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1919::374</td>\n",
       "      <td>1919</td>\n",
       "      <td>374</td>\n",
       "      <td>99</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1920::375</td>\n",
       "      <td>1920</td>\n",
       "      <td>375</td>\n",
       "      <td>100</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1921::376</td>\n",
       "      <td>1921</td>\n",
       "      <td>376</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1922::377</td>\n",
       "      <td>1922</td>\n",
       "      <td>377</td>\n",
       "      <td>87</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1924::379</td>\n",
       "      <td>1924</td>\n",
       "      <td>379</td>\n",
       "      <td>98</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4178 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  patient_id  scan_id  n_slice   label\n",
       "0       0::3131           0     3131      285      CP\n",
       "1       0::3132           0     3132       42      CP\n",
       "2       0::3133           0     3133      290      CP\n",
       "3       0::3134           0     3134       37      CP\n",
       "4       0::3135           0     3135      269      CP\n",
       "...         ...         ...      ...      ...     ...\n",
       "4173  1919::374        1919      374       99  Normal\n",
       "4174  1920::375        1920      375      100  Normal\n",
       "4175  1921::376        1921      376       80  Normal\n",
       "4176  1922::377        1922      377       87  Normal\n",
       "4177  1924::379        1924      379       98  Normal\n",
       "\n",
       "[4178 rows x 5 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pd = labels.toPandas()\n",
    "\n",
    "labels_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4178, 2742)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.select(\"patient_id\").count(), labels.select(\"patient_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do any patient_ids have more than 1 label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\\\n",
    "    .groupBy(\"patient_id\")\\\n",
    "    .agg(F.countDistinct(\"label\").alias(\"num_labels\"))\\\n",
    "    .filter(\"num_labels > 1\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number labels with / without unique patient ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4178, 411529)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels = labels.count()\n",
    "total_slices = labels.selectExpr(\"sum(n_slice) AS total\").first().total\n",
    "\n",
    "total_labels, total_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+---------+---------+\n",
      "| label|count|n_slice|count_pct|slice_pct|\n",
      "+------+-----+-------+---------+---------+\n",
      "|    CP| 1556| 159702|   0.3724|   0.3881|\n",
      "|   NCP| 1544| 156071|   0.3696|   0.3792|\n",
      "|Normal| 1078|  95756|    0.258|   0.2327|\n",
      "+------+-----+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.sum(\"n_slice\").alias(\"n_slice\")\n",
    "    )\\\n",
    "    .withColumn(\"count_pct\", F.expr(f\"ROUND(count / {total_labels}, 4)\"))\\\n",
    "    .withColumn(\"slice_pct\", F.expr(f\"ROUND(n_slice / {total_slices}, 4)\"))\\\n",
    "    .orderBy(\"label\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "| label|count|   pct|\n",
      "+------+-----+------+\n",
      "|    CP|  964|0.3516|\n",
      "|   NCP|  929|0.3388|\n",
      "|Normal|  849|0.3096|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_patients = labels.select(\"patient_id\").distinct().count()\n",
    "labels\\\n",
    "    .dropDuplicates([\"patient_id\"])\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .count()\\\n",
    "    .withColumn(\"pct\", F.expr(f\"ROUND(count / {unique_patients}, 4)\"))\\\n",
    "    .orderBy(\"label\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check labels with metadata only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels with metadata: 378\n",
      "Total slices with metadata: 31616\n",
      "+------+-----+-------+---------+---------+\n",
      "| label|count|n_slice|count_pct|slice_pct|\n",
      "+------+-----+-------+---------+---------+\n",
      "|    CP|  170|  16084|   0.4497|   0.5087|\n",
      "|   NCP|   13|    661|   0.0344|   0.0209|\n",
      "|Normal|  195|  14871|   0.5159|   0.4704|\n",
      "+------+-----+-------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_labels_with_metadata = labels_with_metadata.count()\n",
    "total_slices_with_metadata = labels_with_metadata.selectExpr(\"sum(n_slice) AS total\").first().total\n",
    "\n",
    "print(f\"Total labels with metadata: {total_labels_with_metadata}\")\n",
    "print(f\"Total slices with metadata: {total_slices_with_metadata}\")\n",
    "\n",
    "labels_with_metadata\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.sum(\"n_slice\").alias(\"n_slice\")\n",
    "    )\\\n",
    "    .withColumn(\"count_pct\", F.expr(f\"ROUND(count / {total_labels_with_metadata}, 4)\"))\\\n",
    "    .withColumn(\"slice_pct\", F.expr(f\"ROUND(n_slice / {total_slices_with_metadata}, 4)\"))\\\n",
    "    .orderBy(\"label\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 276 unique patients with metadata\n",
      "+------+-----+------+\n",
      "| label|count|   pct|\n",
      "+------+-----+------+\n",
      "|    CP|   99|0.3587|\n",
      "|   NCP|   13|0.0471|\n",
      "|Normal|  164|0.5942|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_patients_with_metadata = labels_with_metadata.select(\"patient_id\").distinct().count()\n",
    "\n",
    "print(f\"There are {unique_patients_with_metadata} unique patients with metadata\")\n",
    "labels_with_metadata\\\n",
    "    .dropDuplicates([\"patient_id\"])\\\n",
    "    .groupBy(\"label\")\\\n",
    "    .count()\\\n",
    "    .withColumn(\"pct\", F.expr(f\"ROUND(count / {unique_patients_with_metadata}, 4)\"))\\\n",
    "    .orderBy(\"label\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There is almost no metadata for patients with NCP (there's metadata only for 13). It could be usable if we only want to consider e.g. CP VS Normal, but won't be useful for NCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f13d0ab41df452ca27443ccb5417aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=6.0), HTML(value='')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ad94f492d0436899fbb6ac50119410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=5.0), HTML(value='')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd74df870ed44696ad37a39b3b0753dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, layout=Layout(flex='2'), max=1.0), HTML(value='')), la…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "report = sv.analyze(labels_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
