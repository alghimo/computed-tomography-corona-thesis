{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nb_init.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = Path.cwd().parent\n",
    "config_dir = base_dir / \"config\"\n",
    "data_dir = base_dir / \"data\"\n",
    "docs_dir = base_dir / \"docs\"\n",
    "figures_dir = docs_dir / \"figures\"\n",
    "models_dir = base_dir / \"models\"\n",
    "logs_dir = base_dir / \"logs\"\n",
    "images_input_dir = data_dir / \"COVID19\"\n",
    "preprocessed_dir = data_dir / \"preprocessed\"\n",
    "output_dir = data_dir / \"output\"\n",
    "\n",
    "# Directories used to train the CNN (image by image) \n",
    "cnn_data_dir = data_dir / \"modelling\" / \"cnn\"\n",
    "cnn_train_dir = cnn_data_dir / \"train\"\n",
    "cnn_test_dir = cnn_data_dir / \"test\"\n",
    "\n",
    "metadata_file = images_input_dir / \"metadata.csv\"\n",
    "labels_file = images_input_dir / \"unzip_filenames.csv\"\n",
    "preprocessed_labels_file = preprocessed_dir / \"labels.parquet\"\n",
    "\n",
    "feature_extractor_model_file = models_dir / \"feature_extractor.tf\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "config_file = config_dir / \"tfg.conf\"\n",
    "\n",
    "from pyhocon import ConfigFactory\n",
    "config = None\n",
    "\n",
    "def load_config():\n",
    "    return ConfigFactory.parse_file(config_file)\n",
    "\n",
    "config = load_config()\n",
    "    \n",
    "import sys\n",
    "\n",
    "if str(base_dir / \"src\") not in sys.path:\n",
    "    sys.path.append(str(base_dir / \"src\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.235:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5de78d8040>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfg import DataRepository\n",
    "\n",
    "repo = DataRepository(config=config, base_data_path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = {'CP': 0, 'NCP': 1, 'Normal': 2}\n",
    "idx_to_class = { v: k for k, v in class_idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>label</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>clip_num</th>\n",
       "      <th>clip_start_file</th>\n",
       "      <th>clip_end_file</th>\n",
       "      <th>seq_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>CP/0/3131/0000.png</td>\n",
       "      <td>CP/0/3131/0069.png</td>\n",
       "      <td>[[0.0, 0.0, 2.9882235527038574, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>CP/0/3131/0070.png</td>\n",
       "      <td>CP/0/3131/0139.png</td>\n",
       "      <td>[[0.0, 0.015588469803333282, 2.548190832138061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>CP/0/3131/0140.png</td>\n",
       "      <td>CP/0/3131/0209.png</td>\n",
       "      <td>[[0.3391307592391968, 0.016530275344848633, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>3</td>\n",
       "      <td>CP/0/3131/0210.png</td>\n",
       "      <td>CP/0/3131/0279.png</td>\n",
       "      <td>[[0.29484760761260986, 0.0, 1.7729129791259766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>CP/0/3131/0280.png</td>\n",
       "      <td>CP/0/3131/0284.png</td>\n",
       "      <td>[[2.112011671066284, 0.0, 3.815093755722046, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  scan_id label  n_slice  clip_num     clip_start_file  \\\n",
       "0           0     3131    CP      285         0  CP/0/3131/0000.png   \n",
       "1           0     3131    CP      285         1  CP/0/3131/0070.png   \n",
       "2           0     3131    CP      285         2  CP/0/3131/0140.png   \n",
       "3           0     3131    CP      285         3  CP/0/3131/0210.png   \n",
       "4           0     3131    CP      285         4  CP/0/3131/0280.png   \n",
       "\n",
       "        clip_end_file                                       seq_features  \n",
       "0  CP/0/3131/0069.png  [[0.0, 0.0, 2.9882235527038574, 0.0, 0.0, 0.0,...  \n",
       "1  CP/0/3131/0139.png  [[0.0, 0.015588469803333282, 2.548190832138061...  \n",
       "2  CP/0/3131/0209.png  [[0.3391307592391968, 0.016530275344848633, 2....  \n",
       "3  CP/0/3131/0279.png  [[0.29484760761260986, 0.0, 1.7729129791259766...  \n",
       "4  CP/0/3131/0284.png  [[2.112011671066284, 0.0, 3.815093755722046, 0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = repo.load(\"train_clips\")\n",
    "train_clips.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_single_nparr(arrs):\n",
    "    return np.array([el.tolist() for el  in arrs.tolist()])\n",
    "\n",
    "def ohe_label(label):\n",
    "    ohe_labels = [0, 0, 0]\n",
    "    ohe_labels[class_idx[label]] = 1\n",
    "    \n",
    "    return np.array(ohe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]),\n",
       " array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets = train_clips[\"label\"].apply(ohe_label).values\n",
    "train_targets = to_single_nparr(train_targets)\n",
    "train_targets[:5], train_targets[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([array([[0.        , 0.        , 2.98822355, ..., 0.72927612, 0.        ,\n",
       "         0.44937783],\n",
       "        [0.36093032, 0.        , 4.37772894, ..., 1.30455339, 0.        ,\n",
       "         1.11693501],\n",
       "        [0.98390299, 0.        , 3.60125709, ..., 1.25560212, 0.        ,\n",
       "         1.22812939],\n",
       "        ...,\n",
       "        [0.        , 0.06825965, 1.86592245, ..., 0.05172634, 0.        ,\n",
       "         0.        ],\n",
       "        [0.81235242, 0.2658385 , 4.02565336, ..., 0.        , 0.56523615,\n",
       "         0.        ],\n",
       "        [2.29294705, 0.        , 4.27155209, ..., 1.46142101, 0.        ,\n",
       "         1.49820328]])], dtype=object),\n",
       " array([array([[0.        , 1.02570331, 0.        , ..., 0.        , 0.77238965,\n",
       "         0.        ],\n",
       "        [0.        , 1.11100841, 0.        , ..., 0.        , 0.84015405,\n",
       "         0.        ],\n",
       "        [0.        , 2.30372715, 0.60316122, ..., 0.        , 1.95132911,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 2.52368426, 0.        , ..., 0.        , 2.12280846,\n",
       "         0.        ],\n",
       "        [0.        , 1.17681611, 0.        , ..., 0.        , 0.91228163,\n",
       "         0.        ],\n",
       "        [0.        , 3.71051121, 1.2288599 , ..., 0.        , 2.91495275,\n",
       "         0.        ]])], dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_clips[\"seq_features\"].apply(to_single_nparr).values\n",
    "train_data[:1], train_data[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6117,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6117, 70, 32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_obs, seq_length, num_feats = train_data.shape[0], train_data[0].shape[0], train_data[0].shape[1]\n",
    "new_shape = (num_obs, seq_length, num_feats)\n",
    "new_training_data = np.zeros(new_shape)\n",
    "new_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this we make sure that the final data is a single numpy array\n",
    "for idx, obs in enumerate(train_data):\n",
    "    if len(obs) < seq_length:\n",
    "        for feat_idx, feats in enumerate(obs):\n",
    "            new_training_data[idx][feat_idx] = feats\n",
    "    else:\n",
    "        new_training_data[idx] = obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>label</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>clip_num</th>\n",
       "      <th>clip_start_file</th>\n",
       "      <th>clip_end_file</th>\n",
       "      <th>seq_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>CP/4/3505/0000.png</td>\n",
       "      <td>CP/4/3505/0069.png</td>\n",
       "      <td>[[2.613647699356079, 0.0, 0.9890813827514648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>CP/4/3505/0070.png</td>\n",
       "      <td>CP/4/3505/0139.png</td>\n",
       "      <td>[[3.2934000492095947, 0.0, 5.15690279006958, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>CP/4/3505/0140.png</td>\n",
       "      <td>CP/4/3505/0209.png</td>\n",
       "      <td>[[3.833109140396118, 0.0, 5.286610126495361, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>CP/4/3505/0210.png</td>\n",
       "      <td>CP/4/3505/0279.png</td>\n",
       "      <td>[[3.43273663520813, 0.0, 0.621675968170166, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>CP/4/3505/0280.png</td>\n",
       "      <td>CP/4/3505/0297.png</td>\n",
       "      <td>[[4.024286270141602, 0.0, 1.0903337001800537, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  scan_id label  n_slice  clip_num     clip_start_file  \\\n",
       "0           4     3505    CP      298         0  CP/4/3505/0000.png   \n",
       "1           4     3505    CP      298         1  CP/4/3505/0070.png   \n",
       "2           4     3505    CP      298         2  CP/4/3505/0140.png   \n",
       "3           4     3505    CP      298         3  CP/4/3505/0210.png   \n",
       "4           4     3505    CP      298         4  CP/4/3505/0280.png   \n",
       "\n",
       "        clip_end_file                                       seq_features  \n",
       "0  CP/4/3505/0069.png  [[2.613647699356079, 0.0, 0.9890813827514648, ...  \n",
       "1  CP/4/3505/0139.png  [[3.2934000492095947, 0.0, 5.15690279006958, 0...  \n",
       "2  CP/4/3505/0209.png  [[3.833109140396118, 0.0, 5.286610126495361, 0...  \n",
       "3  CP/4/3505/0279.png  [[3.43273663520813, 0.0, 0.621675968170166, 0....  \n",
       "4  CP/4/3505/0297.png  [[4.024286270141602, 0.0, 1.0903337001800537, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_clips = repo.load(\"val_clips\")\n",
    "val_clips.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]]),\n",
       " array([[0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets = val_clips[\"label\"].apply(ohe_label).values\n",
    "val_targets = to_single_nparr(val_targets)\n",
    "val_targets[:5], val_targets[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([array([[2.6136477 , 0.        , 0.98908138, ..., 0.80635095, 0.        ,\n",
       "         0.83522969],\n",
       "        [3.08556819, 0.        , 1.16019964, ..., 0.82768691, 0.        ,\n",
       "         0.94938755],\n",
       "        [3.13986325, 0.        , 2.20502305, ..., 1.3187505 , 0.        ,\n",
       "         1.50978446],\n",
       "        ...,\n",
       "        [3.3429215 , 0.        , 4.32882261, ..., 1.8979671 , 0.        ,\n",
       "         2.183213  ],\n",
       "        [3.63964081, 0.        , 4.41138649, ..., 1.97474813, 0.        ,\n",
       "         2.31390309],\n",
       "        [3.54425406, 0.        , 5.61092615, ..., 2.367167  , 0.        ,\n",
       "         2.77212691]])], dtype=object),\n",
       " array([array([[0.        , 0.40822747, 0.        , ..., 0.        , 0.46930605,\n",
       "         0.        ],\n",
       "        [0.44518673, 0.14363712, 0.        , ..., 0.        , 0.18813239,\n",
       "         0.        ],\n",
       "        [0.74548346, 0.14900705, 0.        , ..., 0.        , 0.20418029,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.22963272, 0.        , 1.32374883, ..., 0.81885922, 0.        ,\n",
       "         0.72018564],\n",
       "        [0.09062506, 0.        , 1.32814097, ..., 0.79093397, 0.        ,\n",
       "         0.6984272 ],\n",
       "        [0.00833891, 0.        , 0.83149099, ..., 0.61896998, 0.        ,\n",
       "         0.49784034]])], dtype=object))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = val_clips[\"seq_features\"].apply(to_single_nparr).values\n",
    "val_data[:1], val_data[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 70, 32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_val_obs = val_data.shape[0]\n",
    "new_val_shape = (num_val_obs, seq_length, num_feats)\n",
    "new_val_data = np.zeros(new_val_shape)\n",
    "new_val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this we make sure that the final data is a single numpy array\n",
    "for idx, obs in enumerate(val_data):\n",
    "    if len(obs) < seq_length:\n",
    "        for feat_idx, feats in enumerate(obs):\n",
    "            new_val_data[idx][feat_idx] = feats\n",
    "    else:\n",
    "        new_val_data[idx] = obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_bidirect_1 (Bidirectiona (None, 70, 32)            4800      \n",
      "_________________________________________________________________\n",
      "gru_bidirect_2 (Bidirectiona (None, 16)                2016      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 6,979\n",
      "Trainable params: 6,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "num_recurrent_units = 16\n",
    "seq_length = 70\n",
    "\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.GRU(num_recurrent_units, return_sequences=True), input_shape=(seq_length, num_features), name=\"gru_bidirect_1\")\n",
    ")\n",
    "model.add(layers.Bidirectional(layers.GRU(num_recurrent_units // 2), name=\"gru_bidirect_2\"))\n",
    "# model.add(\n",
    "#     layers.GRU(64, return_sequences=True, input_shape=(seq_length, num_features))\n",
    "# )\n",
    "# model.add(layers.GRU(num_features // 2))\n",
    "model.add(layers.Dense(min(10, num_recurrent_units // 2)))\n",
    "model.add(layers.Dense(3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 5.9557 - categorical_accuracy: 0.4571 - val_loss: 3.8142 - val_categorical_accuracy: 0.6183\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 4.3353 - categorical_accuracy: 0.6158 - val_loss: 4.0297 - val_categorical_accuracy: 0.6398\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.4954 - categorical_accuracy: 0.6173 - val_loss: 4.2462 - val_categorical_accuracy: 0.6398\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.6086 - categorical_accuracy: 0.6152 - val_loss: 4.4411 - val_categorical_accuracy: 0.6290\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.7851 - categorical_accuracy: 0.6137 - val_loss: 4.6578 - val_categorical_accuracy: 0.6277\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.9300 - categorical_accuracy: 0.6144 - val_loss: 4.7228 - val_categorical_accuracy: 0.6277\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.9485 - categorical_accuracy: 0.6145 - val_loss: 4.7228 - val_categorical_accuracy: 0.6277\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.9485 - categorical_accuracy: 0.6145 - val_loss: 4.7228 - val_categorical_accuracy: 0.6277\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 4.9485 - categorical_accuracy: 0.6145 - val_loss: 4.7228 - val_categorical_accuracy: 0.6277\n",
      "Epoch 10/20\n",
      "175/192 [==========================>...] - ETA: 0s - loss: 5.0196 - categorical_accuracy: 0.6104"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "    x=new_training_data, y=train_targets,\n",
    "    batch_size=32, epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=(new_val_data, val_targets)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 6.9935 - categorical_accuracy: 0.5601 - val_loss: 7.7358 - val_categorical_accuracy: 0.5228\n",
      "Epoch 7/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.1146 - categorical_accuracy: 0.5602 - val_loss: 7.7569 - val_categorical_accuracy: 0.5161\n",
      "Epoch 8/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.3622 - categorical_accuracy: 0.5544 - val_loss: 7.7997 - val_categorical_accuracy: 0.5040\n",
      "Epoch 9/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.5625 - categorical_accuracy: 0.5432 - val_loss: 8.1027 - val_categorical_accuracy: 0.5000\n",
      "Epoch 10/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.6072 - categorical_accuracy: 0.5383 - val_loss: 8.1242 - val_categorical_accuracy: 0.5013\n",
      "Epoch 11/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.7416 - categorical_accuracy: 0.5295 - val_loss: 8.1025 - val_categorical_accuracy: 0.4946\n",
      "Epoch 12/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 7.8944 - categorical_accuracy: 0.5215 - val_loss: 8.2324 - val_categorical_accuracy: 0.4919\n",
      "Epoch 13/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 8.0736 - categorical_accuracy: 0.5156 - val_loss: 8.4057 - val_categorical_accuracy: 0.4879\n",
      "Epoch 14/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 8.2738 - categorical_accuracy: 0.5130 - val_loss: 8.5140 - val_categorical_accuracy: 0.4879\n",
      "Epoch 15/15\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 8.5795 - categorical_accuracy: 0.5094 - val_loss: 8.7090 - val_categorical_accuracy: 0.4892\n"
     ]
    }
   ],
   "source": [
    "fit_history2 = model.fit(\n",
    "    x=new_training_data, y=train_targets,\n",
    "    batch_size=32, epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=(new_val_data, val_targets),\n",
    "    initial_epoch=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Trains the model for a fixed number of epochs (iterations on a dataset).\n",
       "\n",
       "Arguments:\n",
       "    x: Input data. It could be:\n",
       "      - A Numpy array (or array-like), or a list of arrays\n",
       "        (in case the model has multiple inputs).\n",
       "      - A TensorFlow tensor, or a list of tensors\n",
       "        (in case the model has multiple inputs).\n",
       "      - A dict mapping input names to the corresponding array/tensors,\n",
       "        if the model has named inputs.\n",
       "      - A `tf.data` dataset. Should return a tuple\n",
       "        of either `(inputs, targets)` or\n",
       "        `(inputs, targets, sample_weights)`.\n",
       "      - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
       "        or `(inputs, targets, sample_weights)`.\n",
       "      A more detailed description of unpacking behavior for iterator types\n",
       "      (Dataset, generator, Sequence) is given below.\n",
       "    y: Target data. Like the input data `x`,\n",
       "      it could be either Numpy array(s) or TensorFlow tensor(s).\n",
       "      It should be consistent with `x` (you cannot have Numpy inputs and\n",
       "      tensor targets, or inversely). If `x` is a dataset, generator,\n",
       "      or `keras.utils.Sequence` instance, `y` should\n",
       "      not be specified (since targets will be obtained from `x`).\n",
       "    batch_size: Integer or `None`.\n",
       "        Number of samples per gradient update.\n",
       "        If unspecified, `batch_size` will default to 32.\n",
       "        Do not specify the `batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    epochs: Integer. Number of epochs to train the model.\n",
       "        An epoch is an iteration over the entire `x` and `y`\n",
       "        data provided.\n",
       "        Note that in conjunction with `initial_epoch`,\n",
       "        `epochs` is to be understood as \"final epoch\".\n",
       "        The model is not trained for a number of iterations\n",
       "        given by `epochs`, but merely until the epoch\n",
       "        of index `epochs` is reached.\n",
       "    verbose: 0, 1, or 2. Verbosity mode.\n",
       "        0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
       "        Note that the progress bar is not particularly useful when\n",
       "        logged to a file, so verbose=2 is recommended when not running\n",
       "        interactively (eg, in a production environment).\n",
       "    callbacks: List of `keras.callbacks.Callback` instances.\n",
       "        List of callbacks to apply during training.\n",
       "        See `tf.keras.callbacks`.\n",
       "    validation_split: Float between 0 and 1.\n",
       "        Fraction of the training data to be used as validation data.\n",
       "        The model will set apart this fraction of the training data,\n",
       "        will not train on it, and will evaluate\n",
       "        the loss and any model metrics\n",
       "        on this data at the end of each epoch.\n",
       "        The validation data is selected from the last samples\n",
       "        in the `x` and `y` data provided, before shuffling. This argument is\n",
       "        not supported when `x` is a dataset, generator or\n",
       "       `keras.utils.Sequence` instance.\n",
       "    validation_data: Data on which to evaluate\n",
       "        the loss and any model metrics at the end of each epoch.\n",
       "        The model will not be trained on this data.\n",
       "        `validation_data` will override `validation_split`.\n",
       "        `validation_data` could be:\n",
       "          - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
       "          - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
       "          - dataset\n",
       "        For the first two cases, `batch_size` must be provided.\n",
       "        For the last case, `validation_steps` could be provided.\n",
       "        Note that `validation_data` does not support all the data types that\n",
       "        are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
       "    shuffle: Boolean (whether to shuffle the training data\n",
       "        before each epoch) or str (for 'batch'). This argument is ignored\n",
       "        when `x` is a generator. 'batch' is a special option for dealing\n",
       "        with the limitations of HDF5 data; it shuffles in batch-sized\n",
       "        chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
       "    class_weight: Optional dictionary mapping class indices (integers)\n",
       "        to a weight (float) value, used for weighting the loss function\n",
       "        (during training only).\n",
       "        This can be useful to tell the model to\n",
       "        \"pay more attention\" to samples from\n",
       "        an under-represented class.\n",
       "    sample_weight: Optional Numpy array of weights for\n",
       "        the training samples, used for weighting the loss function\n",
       "        (during training only). You can either pass a flat (1D)\n",
       "        Numpy array with the same length as the input samples\n",
       "        (1:1 mapping between weights and samples),\n",
       "        or in the case of temporal data,\n",
       "        you can pass a 2D array with shape\n",
       "        `(samples, sequence_length)`,\n",
       "        to apply a different weight to every timestep of every sample.\n",
       "        In this case you should make sure to specify\n",
       "        `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
       "        supported when `x` is a dataset, generator, or\n",
       "       `keras.utils.Sequence` instance, instead provide the sample_weights\n",
       "        as the third element of `x`.\n",
       "    initial_epoch: Integer.\n",
       "        Epoch at which to start training\n",
       "        (useful for resuming a previous training run).\n",
       "    steps_per_epoch: Integer or `None`.\n",
       "        Total number of steps (batches of samples)\n",
       "        before declaring one epoch finished and starting the\n",
       "        next epoch. When training with input tensors such as\n",
       "        TensorFlow data tensors, the default `None` is equal to\n",
       "        the number of samples in your dataset divided by\n",
       "        the batch size, or 1 if that cannot be determined. If x is a\n",
       "        `tf.data` dataset, and 'steps_per_epoch'\n",
       "        is None, the epoch will run until the input dataset is exhausted.\n",
       "        When passing an infinitely repeating dataset, you must specify the\n",
       "        `steps_per_epoch` argument. This argument is not supported with\n",
       "        array inputs.\n",
       "    validation_steps: Only relevant if `validation_data` is provided and\n",
       "        is a `tf.data` dataset. Total number of steps (batches of\n",
       "        samples) to draw before stopping when performing validation\n",
       "        at the end of every epoch. If 'validation_steps' is None, validation\n",
       "        will run until the `validation_data` dataset is exhausted. In the\n",
       "        case of an infinitely repeated dataset, it will run into an\n",
       "        infinite loop. If 'validation_steps' is specified and only part of\n",
       "        the dataset will be consumed, the evaluation will start from the\n",
       "        beginning of the dataset at each epoch. This ensures that the same\n",
       "        validation samples are used every time.\n",
       "    validation_batch_size: Integer or `None`.\n",
       "        Number of samples per validation batch.\n",
       "        If unspecified, will default to `batch_size`.\n",
       "        Do not specify the `validation_batch_size` if your data is in the\n",
       "        form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "        (since they generate batches).\n",
       "    validation_freq: Only relevant if validation data is provided. Integer\n",
       "        or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
       "        If an integer, specifies how many training epochs to run before a\n",
       "        new validation run is performed, e.g. `validation_freq=2` runs\n",
       "        validation every 2 epochs. If a Container, specifies the epochs on\n",
       "        which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
       "        validation at the end of the 1st, 2nd, and 10th epochs.\n",
       "    max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
       "        input only. Maximum size for the generator queue.\n",
       "        If unspecified, `max_queue_size` will default to 10.\n",
       "    workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "        only. Maximum number of processes to spin up\n",
       "        when using process-based threading. If unspecified, `workers`\n",
       "        will default to 1. If 0, will execute the generator on the main\n",
       "        thread.\n",
       "    use_multiprocessing: Boolean. Used for generator or\n",
       "        `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "        threading. If unspecified, `use_multiprocessing` will default to\n",
       "        `False`. Note that because this implementation relies on\n",
       "        multiprocessing, you should not pass non-picklable arguments to\n",
       "        the generator as they can't be passed easily to children processes.\n",
       "\n",
       "Unpacking behavior for iterator-like inputs:\n",
       "    A common pattern is to pass a tf.data.Dataset, generator, or\n",
       "  tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
       "  yield not only features (x) but optionally targets (y) and sample weights.\n",
       "  Keras requires that the output of such iterator-likes be unambiguous. The\n",
       "  iterator should return a tuple of length 1, 2, or 3, where the optional\n",
       "  second and third elements will be used for y and sample_weight\n",
       "  respectively. Any other type provided will be wrapped in a length one\n",
       "  tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
       "  should still adhere to the top-level tuple structure.\n",
       "  e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
       "  features, targets, and weights from the keys of a single dict.\n",
       "    A notable unsupported data type is the namedtuple. The reason is that\n",
       "  it behaves like both an ordered datatype (tuple) and a mapping\n",
       "  datatype (dict). So given a namedtuple of the form:\n",
       "      `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
       "  it is ambiguous whether to reverse the order of the elements when\n",
       "  interpreting the value. Even worse is a tuple of the form:\n",
       "      `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
       "  where it is unclear if the tuple was intended to be unpacked into x, y,\n",
       "  and sample_weight or passed through as a single element to `x`. As a\n",
       "  result the data processing code will simply raise a ValueError if it\n",
       "  encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
       "\n",
       "Returns:\n",
       "    A `History` object. Its `History.history` attribute is\n",
       "    a record of training loss values and metrics values\n",
       "    at successive epochs, as well as validation loss values\n",
       "    and validation metrics values (if applicable).\n",
       "\n",
       "Raises:\n",
       "    RuntimeError: If the model was never compiled.\n",
       "    ValueError: In case of mismatch between the provided input data\n",
       "        and what the model expects.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tfg/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"covid_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_images (InputLayer)    [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_01 (Conv2D)           (None, 128, 128, 6)       168       \n",
      "_________________________________________________________________\n",
      "maxpool2d_01 (MaxPooling2D)  (None, 64, 64, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_02 (Conv2D)           (None, 64, 64, 12)        660       \n",
      "_________________________________________________________________\n",
      "maxpool2d_02 (MaxPooling2D)  (None, 32, 32, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_03 (Conv2D)           (None, 32, 32, 24)        2616      \n",
      "_________________________________________________________________\n",
      "maxpool2d_03 (MaxPooling2D)  (None, 16, 16, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_04 (Conv2D)           (None, 16, 16, 48)        10416     \n",
      "_________________________________________________________________\n",
      "maxpool2d_04 (MaxPooling2D)  (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_05 (Conv2D)           (None, 8, 8, 96)          41568     \n",
      "_________________________________________________________________\n",
      "dropout__05 (Dropout)        (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "maxpool2d_05 (MaxPooling2D)  (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_01 (Dense)             (None, 64)                98368     \n",
      "_________________________________________________________________\n",
      "dropout_01 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_02 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_02 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 155,975\n",
      "Trainable params: 155,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn_model_suffix = \"06\"\n",
    "model_file = models_dir / f\"feature_extractor_{cnn_model_suffix}.tf\"\n",
    "model = load_model(str(model_file))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f5be0305460>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f5be0305c70>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f5be02d09a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f5be02d0eb0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f5be026faf0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f5be026ffd0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f5be0273c40>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f5be0277190>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f5be0277d90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f5be027d2e0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f5be027de20>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f5be02893a0>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x7f5be02897c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f5be0289c10>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x7f5be028d550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f5be028d820>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers[:-1]:\n",
    "    if isinstance(l, tf.python.keras.layers.core.Dropout):\n",
    "        continue\n",
    "    new_model.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_01 (Conv2D)           (None, 128, 128, 6)       168       \n",
      "_________________________________________________________________\n",
      "maxpool2d_01 (MaxPooling2D)  (None, 64, 64, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_02 (Conv2D)           (None, 64, 64, 12)        660       \n",
      "_________________________________________________________________\n",
      "maxpool2d_02 (MaxPooling2D)  (None, 32, 32, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_03 (Conv2D)           (None, 32, 32, 24)        2616      \n",
      "_________________________________________________________________\n",
      "maxpool2d_03 (MaxPooling2D)  (None, 16, 16, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_04 (Conv2D)           (None, 16, 16, 48)        10416     \n",
      "_________________________________________________________________\n",
      "maxpool2d_04 (MaxPooling2D)  (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_05 (Conv2D)           (None, 8, 8, 96)          41568     \n",
      "_________________________________________________________________\n",
      "maxpool2d_05 (MaxPooling2D)  (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_01 (Dense)             (None, 64)                98368     \n",
      "_________________________________________________________________\n",
      "dense_02 (Dense)             (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 155,876\n",
      "Trainable params: 155,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0275.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0064.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0083.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0160.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/0/3131/0127.png</td>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                file  patient_id  scan_id  n_slice  num_clips  seq_num  \\\n",
       "0    CP  CP/0/3131/0275.png           0     3131      285          0        0   \n",
       "1    CP  CP/0/3131/0064.png           0     3131      285          0        1   \n",
       "2    CP  CP/0/3131/0083.png           0     3131      285          0        2   \n",
       "3    CP  CP/0/3131/0160.png           0     3131      285          0        3   \n",
       "4    CP  CP/0/3131/0127.png           0     3131      285          0        4   \n",
       "\n",
       "   clip_num  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = repo.load(\"train_df\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the num_clips, seq_num and clip_num are not correct, we'll fix them.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "images_per_clip = config.get_int(\"tfg.training.images_per_clip\")\n",
    "\n",
    "scan_window = Window\\\n",
    "    .partitionBy(\"patient_id\", \"scan_id\")\\\n",
    "    .orderBy(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_df(pandas_df):\n",
    "    df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "    new_df = df\\\n",
    "        .withColumn(\"seq_num\", F.row_number().over(scan_window) - 1)\\\n",
    "        .withColumn(\"num_clips\", F.ceil(F.col(\"n_slice\") / images_per_clip))\\\n",
    "        .withColumn(\"clip_num\", F.floor(F.col(\"seq_num\") / images_per_clip))\\\n",
    "        .toPandas()\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP</td>\n",
       "      <td>NCP/880/2415/0000.jpg</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP</td>\n",
       "      <td>NCP/880/2415/0001.jpg</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP</td>\n",
       "      <td>NCP/880/2415/0002.jpg</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP</td>\n",
       "      <td>NCP/880/2415/0003.jpg</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP</td>\n",
       "      <td>NCP/880/2415/0004.jpg</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                   file  patient_id  scan_id  n_slice  num_clips  \\\n",
       "0   NCP  NCP/880/2415/0000.jpg         880     2415      312          5   \n",
       "1   NCP  NCP/880/2415/0001.jpg         880     2415      312          5   \n",
       "2   NCP  NCP/880/2415/0002.jpg         880     2415      312          5   \n",
       "3   NCP  NCP/880/2415/0003.jpg         880     2415      312          5   \n",
       "4   NCP  NCP/880/2415/0004.jpg         880     2415      312          5   \n",
       "\n",
       "   seq_num  clip_num  \n",
       "0        0         0  \n",
       "1        1         0  \n",
       "2        2         0  \n",
       "3        3         0  \n",
       "4        4         0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = repo.load(\"train_df\")\n",
    "train_df = fix_df(train_df)\n",
    "repo.save(\"train_df\", train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = repo.load(\"val_df\")\n",
    "val_df = fix_df(val_df)\n",
    "repo.save(\"val_df\", val_df)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = repo.load(\"test_df\")\n",
    "test_df = fix_df(test_df)\n",
    "repo.save(\"test_df\", test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images into features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = config.get_int(\"tfg.training.img_size\")\n",
    "image_target_size = (img_size, img_size)\n",
    "seed = config.get_int(\"tfg.seed\")\n",
    "batch_size = config.get_int(\"tfg.training.batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 331286 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_df = repo.load(\"train_df\")\n",
    "train_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=str(images_input_dir),\n",
    "    x_col=\"file\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=image_target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CP': 0, 'NCP': 1, 'Normal': 2}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_generator.class_indices\n",
    "idx_to_class = { v: k for k, v in class_to_idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_BATCHES = train_generator.n // train_generator.batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10353/10353 [==============================] - 2345s 226ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(331286, 32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_feats = new_model.predict(train_generator, steps=NUM_TRAIN_BATCHES, verbose=1)\n",
    "raw_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"img_features\"] = raw_train_feats.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"train_features\", train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "      <th>img_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP/880/2415/0000.jpg</td>\n",
       "      <td>NCP</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 5.270750045776367, 0.0, 5.07415866851806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP/880/2415/0001.jpg</td>\n",
       "      <td>NCP</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 2.8091320991516113, 0.0, 2.9504299163818...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP/880/2415/0002.jpg</td>\n",
       "      <td>NCP</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.616379737854004, 0.19390609860420227, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP/880/2415/0003.jpg</td>\n",
       "      <td>NCP</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 2.734466314315796, 0.0, 2.81957268714904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP/880/2415/0004.jpg</td>\n",
       "      <td>NCP</td>\n",
       "      <td>880</td>\n",
       "      <td>2415</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 9.06471061706543, 0.0, 7.898210525512695...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file label  patient_id  scan_id  n_slice  num_clips  \\\n",
       "0  NCP/880/2415/0000.jpg   NCP         880     2415      312          5   \n",
       "1  NCP/880/2415/0001.jpg   NCP         880     2415      312          5   \n",
       "2  NCP/880/2415/0002.jpg   NCP         880     2415      312          5   \n",
       "3  NCP/880/2415/0003.jpg   NCP         880     2415      312          5   \n",
       "4  NCP/880/2415/0004.jpg   NCP         880     2415      312          5   \n",
       "\n",
       "   seq_num  clip_num                                       img_features  \n",
       "0        0         0  [0.0, 5.270750045776367, 0.0, 5.07415866851806...  \n",
       "1        1         0  [0.0, 2.8091320991516113, 0.0, 2.9504299163818...  \n",
       "2        2         0  [0.0, 3.616379737854004, 0.19390609860420227, ...  \n",
       "3        3         0  [0.0, 2.734466314315796, 0.0, 2.81957268714904...  \n",
       "4        4         0  [0.0, 9.06471061706543, 0.0, 7.898210525512695...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats = repo.load(\"train_features\")\n",
    "train_feats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39828 validated image filenames belonging to 3 classes.\n",
      "1245/1245 [==============================] - 290s 233ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39828, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = repo.load(\"val_df\")\n",
    "\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=str(images_input_dir),\n",
    "    x_col=\"file\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=image_target_size)\n",
    "\n",
    "NUM_VAL_BATCHES = val_generator.n // val_generator.batch_size + 1\n",
    "\n",
    "raw_val_feats = new_model.predict(val_generator, steps=NUM_VAL_BATCHES, verbose=1)\n",
    "raw_val_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>img_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP/1075/3118/0543.jpg</td>\n",
       "      <td>[0.5893998742103577, 0.0, 3.105539083480835, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP/1075/3118/0174.jpg</td>\n",
       "      <td>[2.171123504638672, 0.0, 5.15280818939209, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP/1075/3118/0130.jpg</td>\n",
       "      <td>[2.2265334129333496, 0.0, 6.776073455810547, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP/1075/3118/0525.jpg</td>\n",
       "      <td>[1.0836143493652344, 0.0, 3.375173330307007, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP/1075/3118/0152.jpg</td>\n",
       "      <td>[2.058112621307373, 0.0, 5.975271224975586, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file                                       img_features\n",
       "0  CP/1075/3118/0543.jpg  [0.5893998742103577, 0.0, 3.105539083480835, 0...\n",
       "1  CP/1075/3118/0174.jpg  [2.171123504638672, 0.0, 5.15280818939209, 0.0...\n",
       "2  CP/1075/3118/0130.jpg  [2.2265334129333496, 0.0, 6.776073455810547, 0...\n",
       "3  CP/1075/3118/0525.jpg  [1.0836143493652344, 0.0, 3.375173330307007, 0...\n",
       "4  CP/1075/3118/0152.jpg  [2.058112621307373, 0.0, 5.975271224975586, 0...."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[\"img_features\"] = raw_val_feats.tolist()\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"val_features\", val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40415 validated image filenames belonging to 3 classes.\n",
      "1263/1263 [==============================] - 289s 228ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40415, 32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = repo.load(\"test_df\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=str(images_input_dir),\n",
    "    x_col=\"file\",\n",
    "    y_col=\"label\",\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=image_target_size)\n",
    "\n",
    "NUM_TEST_BATCHES = test_generator.n // test_generator.batch_size + 1\n",
    "\n",
    "raw_test_feats = new_model.predict(test_generator, steps=NUM_TEST_BATCHES, verbose=1)\n",
    "raw_test_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>scan_id</th>\n",
       "      <th>n_slice</th>\n",
       "      <th>num_clips</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>clip_num</th>\n",
       "      <th>img_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0275.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.5805813670158386, 0.0, 1.381737232208252, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0064.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4474046230316162, 0.0, 1.0005760192871094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0083.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.157572939991951, 0.0, 1.0315451622009277, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0160.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4971274733543396, 0.0, 1.757103681564331, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>CP/1/3143/0286.png</td>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.35277533531188965, 2.1408023834228516,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                file  patient_id  scan_id  n_slice  num_clips  seq_num  \\\n",
       "0    CP  CP/1/3143/0275.png           1     3143      300          1        0   \n",
       "1    CP  CP/1/3143/0064.png           1     3143      300          1        1   \n",
       "2    CP  CP/1/3143/0083.png           1     3143      300          1        2   \n",
       "3    CP  CP/1/3143/0160.png           1     3143      300          1        3   \n",
       "4    CP  CP/1/3143/0286.png           1     3143      300          1        4   \n",
       "\n",
       "   clip_num                                       img_features  \n",
       "0         0  [0.5805813670158386, 0.0, 1.381737232208252, 0...  \n",
       "1         0  [0.4474046230316162, 0.0, 1.0005760192871094, ...  \n",
       "2         0  [0.157572939991951, 0.0, 1.0315451622009277, 0...  \n",
       "3         0  [0.4971274733543396, 0.0, 1.757103681564331, 0...  \n",
       "4         0  [0.0, 0.35277533531188965, 2.1408023834228516,...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"img_features\"] = raw_test_feats.tolist()\n",
    "repo.save(\"test_features\", test_df)\n",
    "\n",
    "test_feats = repo.load(\"test_features\")\n",
    "test_feats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group features into clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_features(series):\n",
    "    series = sorted(series, key=lambda t: t[0])\n",
    "    \n",
    "    return [seq_feats[1] for seq_feats in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clips(df):\n",
    "    df[\"seq_features\"] = list(zip(df.seq_num, df.img_features))\n",
    "    df_clips = df\\\n",
    "        .groupby(by=[\"patient_id\", \"scan_id\", \"label\", \"n_slice\", \"clip_num\"])\\\n",
    "        .agg({\n",
    "            'file': [\"min\", \"max\"],\n",
    "            'seq_features': [agg_features]\n",
    "        })\\\n",
    "        .reset_index()\n",
    "\n",
    "    # Takes care of the multi-index after the groupby\n",
    "    df_clips.columns = df_clips.columns.map('_'.join)\n",
    "\n",
    "    df_clips = df_clips.rename(columns={\n",
    "        \"seq_features_agg_features\": \"seq_features\",\n",
    "        \"file_min\": \"clip_start_file\",\n",
    "        \"file_max\": \"clip_end_file\",\n",
    "    })\n",
    "    \n",
    "    return df_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id_</th>\n",
       "      <th>scan_id_</th>\n",
       "      <th>label_</th>\n",
       "      <th>n_slice_</th>\n",
       "      <th>clip_num_</th>\n",
       "      <th>clip_start_file</th>\n",
       "      <th>clip_end_file</th>\n",
       "      <th>seq_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>CP/0/3131/0000.png</td>\n",
       "      <td>CP/0/3131/0069.png</td>\n",
       "      <td>[[0.0, 0.0, 2.9882235527038574, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>CP/0/3131/0070.png</td>\n",
       "      <td>CP/0/3131/0139.png</td>\n",
       "      <td>[[0.0, 0.015588469803333282, 2.548190832138061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>CP/0/3131/0140.png</td>\n",
       "      <td>CP/0/3131/0209.png</td>\n",
       "      <td>[[0.3391307592391968, 0.016530275344848633, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>3</td>\n",
       "      <td>CP/0/3131/0210.png</td>\n",
       "      <td>CP/0/3131/0279.png</td>\n",
       "      <td>[[0.29484760761260986, 0.0, 1.7729129791259766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3131</td>\n",
       "      <td>CP</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>CP/0/3131/0280.png</td>\n",
       "      <td>CP/0/3131/0284.png</td>\n",
       "      <td>[[2.112011671066284, 0.0, 3.815093755722046, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id_  scan_id_ label_  n_slice_  clip_num_     clip_start_file  \\\n",
       "0            0      3131     CP       285          0  CP/0/3131/0000.png   \n",
       "1            0      3131     CP       285          1  CP/0/3131/0070.png   \n",
       "2            0      3131     CP       285          2  CP/0/3131/0140.png   \n",
       "3            0      3131     CP       285          3  CP/0/3131/0210.png   \n",
       "4            0      3131     CP       285          4  CP/0/3131/0280.png   \n",
       "\n",
       "        clip_end_file                                       seq_features  \n",
       "0  CP/0/3131/0069.png  [[0.0, 0.0, 2.9882235527038574, 0.0, 0.0, 0.0,...  \n",
       "1  CP/0/3131/0139.png  [[0.0, 0.015588469803333282, 2.548190832138061...  \n",
       "2  CP/0/3131/0209.png  [[0.3391307592391968, 0.016530275344848633, 2....  \n",
       "3  CP/0/3131/0279.png  [[0.29484760761260986, 0.0, 1.7729129791259766...  \n",
       "4  CP/0/3131/0284.png  [[2.112011671066284, 0.0, 3.815093755722046, 0...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats = repo.load(\"train_features\")\n",
    "train_clips = make_clips(train_feats)\n",
    "train_clips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"train_clips\", train_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id_</th>\n",
       "      <th>scan_id_</th>\n",
       "      <th>label_</th>\n",
       "      <th>n_slice_</th>\n",
       "      <th>clip_num_</th>\n",
       "      <th>clip_start_file</th>\n",
       "      <th>clip_end_file</th>\n",
       "      <th>seq_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>CP/4/3505/0000.png</td>\n",
       "      <td>CP/4/3505/0069.png</td>\n",
       "      <td>[[2.613647699356079, 0.0, 0.9890813827514648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>CP/4/3505/0070.png</td>\n",
       "      <td>CP/4/3505/0139.png</td>\n",
       "      <td>[[3.2934000492095947, 0.0, 5.15690279006958, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>2</td>\n",
       "      <td>CP/4/3505/0140.png</td>\n",
       "      <td>CP/4/3505/0209.png</td>\n",
       "      <td>[[3.833109140396118, 0.0, 5.286610126495361, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>CP/4/3505/0210.png</td>\n",
       "      <td>CP/4/3505/0279.png</td>\n",
       "      <td>[[3.43273663520813, 0.0, 0.621675968170166, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3505</td>\n",
       "      <td>CP</td>\n",
       "      <td>298</td>\n",
       "      <td>4</td>\n",
       "      <td>CP/4/3505/0280.png</td>\n",
       "      <td>CP/4/3505/0297.png</td>\n",
       "      <td>[[4.024286270141602, 0.0, 1.0903337001800537, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id_  scan_id_ label_  n_slice_  clip_num_     clip_start_file  \\\n",
       "0            4      3505     CP       298          0  CP/4/3505/0000.png   \n",
       "1            4      3505     CP       298          1  CP/4/3505/0070.png   \n",
       "2            4      3505     CP       298          2  CP/4/3505/0140.png   \n",
       "3            4      3505     CP       298          3  CP/4/3505/0210.png   \n",
       "4            4      3505     CP       298          4  CP/4/3505/0280.png   \n",
       "\n",
       "        clip_end_file                                       seq_features  \n",
       "0  CP/4/3505/0069.png  [[2.613647699356079, 0.0, 0.9890813827514648, ...  \n",
       "1  CP/4/3505/0139.png  [[3.2934000492095947, 0.0, 5.15690279006958, 0...  \n",
       "2  CP/4/3505/0209.png  [[3.833109140396118, 0.0, 5.286610126495361, 0...  \n",
       "3  CP/4/3505/0279.png  [[3.43273663520813, 0.0, 0.621675968170166, 0....  \n",
       "4  CP/4/3505/0297.png  [[4.024286270141602, 0.0, 1.0903337001800537, ...  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_feats = repo.load(\"val_features\")\n",
    "val_clips = make_clips(val_feats)\n",
    "val_clips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"val_clips\", val_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id_</th>\n",
       "      <th>scan_id_</th>\n",
       "      <th>label_</th>\n",
       "      <th>n_slice_</th>\n",
       "      <th>clip_num_</th>\n",
       "      <th>clip_start_file</th>\n",
       "      <th>clip_end_file</th>\n",
       "      <th>seq_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>CP</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>CP/1/3143/0000.png</td>\n",
       "      <td>CP/1/3143/0069.png</td>\n",
       "      <td>[[0.7901433110237122, 0.0, 0.4899705648422241,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>CP</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>CP/1/3143/0070.png</td>\n",
       "      <td>CP/1/3143/0139.png</td>\n",
       "      <td>[[0.39713576436042786, 0.0, 0.7319959402084351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>CP</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>CP/1/3143/0140.png</td>\n",
       "      <td>CP/1/3143/0209.png</td>\n",
       "      <td>[[0.655151903629303, 0.0, 1.253217101097107, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>CP</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>CP/1/3143/0210.png</td>\n",
       "      <td>CP/1/3143/0279.png</td>\n",
       "      <td>[[1.5254734754562378, 0.0, 3.0512397289276123,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3143</td>\n",
       "      <td>CP</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>CP/1/3143/0280.png</td>\n",
       "      <td>CP/1/3143/0299.png</td>\n",
       "      <td>[[0.0, 0.09542667120695114, 1.2658686637878418...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id_  scan_id_ label_  n_slice_  clip_num_     clip_start_file  \\\n",
       "0            1      3143     CP       300          0  CP/1/3143/0000.png   \n",
       "1            1      3143     CP       300          1  CP/1/3143/0070.png   \n",
       "2            1      3143     CP       300          2  CP/1/3143/0140.png   \n",
       "3            1      3143     CP       300          3  CP/1/3143/0210.png   \n",
       "4            1      3143     CP       300          4  CP/1/3143/0280.png   \n",
       "\n",
       "        clip_end_file                                       seq_features  \n",
       "0  CP/1/3143/0069.png  [[0.7901433110237122, 0.0, 0.4899705648422241,...  \n",
       "1  CP/1/3143/0139.png  [[0.39713576436042786, 0.0, 0.7319959402084351...  \n",
       "2  CP/1/3143/0209.png  [[0.655151903629303, 0.0, 1.253217101097107, 0...  \n",
       "3  CP/1/3143/0279.png  [[1.5254734754562378, 0.0, 3.0512397289276123,...  \n",
       "4  CP/1/3143/0299.png  [[0.0, 0.09542667120695114, 1.2658686637878418...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats = repo.load(\"test_features\")\n",
    "test_clips = make_clips(test_feats)\n",
    "test_clips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo.save(\"test_clips\", test_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
